{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RANZCR CLiP\n- [Basecode](https://www.kaggle.com/sohomdey/ranzcr-clip-efficientnet-auc-0-95-tpu)\n"},{"metadata":{},"cell_type":"markdown","source":"### Accelerator\n- TPU v3-8 [[doc](https://www.kaggle.com/docs/tpu)]\n    - (해결못함) 사용률이 현저히 낮음  \n    - 참고 코드\n        - https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training/data?select=tf_keras_efficientnet.py\n        - https://www.kaggle.com/bbalrangco/five-flowers-on-tpu-with-new-data-augmentation/edit\n\n### Module version\n- Seaborn version 0.10.0\n- Pandas version 1.1.5\n- Numpy version 1.17.5\n- cv2 version 4.41\n- Tenserflow version 2.4.1\n- Sklearn version 0.24.1\n- Tenserflow.keras version 2.4.0\n\n### Database\n- MongoDB server version 4.4.3\n- Python 3.9.1\n- Pycharm 2020.3.3\n- mongoDB Compass 1.25.0","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"## Workflow\n\n* Image preprocessing\n    * (present) Current architecture requires 3 channel inputs, need to fix it.\n    * (later)   Image preprocessing to improve the clarity of images\n    * (later)   More augmentation\n    * (later)   Different image sizes\n* Class balancing\n    * Weighted Loss Functions $\\rightarrow$ tf.keras.callbacks.ReduceLROnPlateau\n    * Oversampling $\\rightarrow$ tf.keras.callbacks.EarlyStopping\n* Architecture tuning\n* Ensembling"},{"metadata":{},"cell_type":"markdown","source":"## Install"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# >> /dev/null : 표준 오류 출력만 무시\n! pip install -q efficientnet >> /dev/null","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import modules\n\n- 평가 메트릭 AUC : tf.keras.metrics.AUC\n- 교차 검증 : KFold (미사용)\n- [mixed_precision](https://www.tensorflow.org/guide/mixed_precision?hl=ko) : 훈련 중에 모델에서 16-bit 및 32-bit 부동 소수점 유형을 모두 사용하여 더 빠르게 실행하고 메모리를 적게 사용 (TPU 환경 'bfloat16' 사용)\n- backend : [tensorflow.keras.backend 사용](https://i-am-eden.tistory.com/2)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\n\nfrom sklearn.model_selection import KFold\n# from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n\nimport efficientnet.tfkeras as efn","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set path"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '/kaggle/input/ranzcr-clip-catheter-line-classification'\n\nMODEL_PATH = '/kaggle/working/models'","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tf record 파일 갯수 확인\n\nNUM_TF_RECS = len(os.listdir(f'{DATA_PATH}/train_tfrecords'))\n\nprint(NUM_TF_RECS)","execution_count":37,"outputs":[{"output_type":"stream","text":"16\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Set parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = 'TPU' # ['CPU' GPU' 'TPU']\n\nENABLE_MIXED_PRECISION = True # [True False]","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nFOLDS = 5 \n\nEFF_NET = 'B0' # ['B0',B1','B2',B3','B4',B5','B6',B7']\n# effnets = {'B0': efn.EfficientNetB0,'B1': efn.EfficientNetB1,'B2': efn.EfficientNetB2,'B3': efn.EfficientNetB3,'B4': efn.EfficientNetB4,'B5': efn.EfficientNetB5,'B6': efn.EfficientNetB6,'B7': efn.EfficientNetB7}\n\nif EFF_NET=='B0':\n    IMG_SIZE = 224\nelif EFF_NET=='B1':\n    IMG_SIZE = 240\nelif EFF_NET=='B2':\n    IMG_SIZE = 260\nelif EFF_NET=='B3':\n    IMG_SIZE = 300\nelif EFF_NET=='B4':\n    IMG_SIZE = 380\nelif EFF_NET=='B5':\n    IMG_SIZE = 456\nelif EFF_NET=='B6':\n    IMG_SIZE = 528\nelif EFF_NET=='B7':\n    IMG_SIZE = 600\n\n\nBATCH_SIZE = 32 # [8, 16, 32, 64, 128, 256, 512]\n\nEPOCHS = 25\n\nVERBOSE = 2 # [0: silent, 1: progress bar, 2: single line]","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup devices and settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For kaggle tpus (Need Internet)\nfrom kaggle_datasets import KaggleDatasets\nif DEVICE == 'TPU':\n    DATA_PATH = KaggleDatasets().get_gcs_path(DATA_PATH.split('/')[-1])","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if DEVICE == 'CPU':\n\n    strategy = tf.distribute.get_strategy()\n    print('\\nUsing Default Distribution Strategy  for CPU')\n\n\nif DEVICE == 'GPU':\n\n    gpu_accelerarors = tf.config.list_physical_devices('GPU')\n        \n    if len(gpu_accelerarors) > 1:\n        strategy = tf.distribute.MirroredStrategy()\n        print(f'Number of GPUs available: {len(gpu_accelerarors)}')\n        print('\\n Using Mirrored Distribution Strategy')\n        \n    else:\n        strategy = tf.distribute.get_strategy()\n        if len(gpu_accelerarors) == 1:\n            print(f'Number of GPUs available: 1')\n            print('\\nUsing Default Distribution Strategy for GPU')\n        else:\n            print('ERROR: GPU not available')\n            print('\\nUsing Default Distribution Strategy  for CPU')\n        \nif DEVICE == 'TPU':\n\n    try:\n        resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(resolver)\n        tf.tpu.experimental.initialize_tpu_system(resolver)\n        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n        tpu_accelerarors = tf.config.list_logical_devices('TPU')\n        print(f'Number of TPU cores available: {len(tpu_accelerarors)}')\n        print(f'\\nUsing TPU Distribution Strategy')\n        \n    except:\n        print('ERROR: TPU not available')\n        print('\\nUsing Default Distribution Strategy for CPU')\n        strategy = tf.distribute.get_strategy()\n        \n        \nif ENABLE_MIXED_PRECISION:\n    \n    print('\\nMixed Precision enabled:')\n    \n    if DEVICE == 'GPU':\n        policy = mixed_precision.Policy('mixed_float16')\n        \n    if DEVICE == 'TPU':\n        policy = mixed_precision.Policy('mixed_bfloat16')\n        \n    mixed_precision.set_policy(policy)\n    \n    print('\\t...Compute dtype: %s' % policy.compute_dtype)\n    print('\\t...Variable dtype: %s' % policy.variable_dtype)\n\n\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'\\nREPLICAS: {REPLICAS}')","execution_count":41,"outputs":[{"output_type":"stream","text":"Number of TPU cores available: 8\n\nUsing TPU Distribution Strategy\n\nMixed Precision enabled:\n\t...Compute dtype: bfloat16\n\t...Variable dtype: float32\n\nREPLICAS: 8\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions\n- 클래스 Dataset : \n    - 클래스 변수 : tf.io.FixedLenFeature([], tf.string) : 고정길이 입력기능 (컬럼별로 지정)\n    - parse_function, generator : [TFRecord 파일 사용](https://limjun92.github.io/assets/TensorFlow%202.0%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/3.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%A1%9C%EB%93%9C%20%EB%B0%8F%20%EC%82%AC%EC%A0%84%20%EC%B2%98%EB%A6%AC/%5B%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC8%5D%20TFRecord%EC%99%80%20tf.Example/)\n    - augment_function : 상하반전, 좌우반전, 채도조절, 명도조절\n    \n- create_model\n    ```\n    model = tf.keras.Sequential([\n    effnets[EFF_NET](\n        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n        weights='imagenet',\n        include_top=False,\n        drop_connect_rate=0.7),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(11, activation='sigmoid')\n    ])\n    \n    ```\n- compile_model\n    ```\n    model.compile(\n    optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n    loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05),\n    metrics=[tf.keras.metrics.AUC(name='auc', multi_label=True)])\n    \n    ```\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset:\n    \n    feature_description = {\n        \"StudyInstanceUID\"           : tf.io.FixedLenFeature([], tf.string),\n        \"image\"                      : tf.io.FixedLenFeature([], tf.string),\n        \"ETT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"ETT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Incompletely Imaged\"  : tf.io.FixedLenFeature([], tf.int64), \n        \"NGT - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Abnormal\"             : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Borderline\"           : tf.io.FixedLenFeature([], tf.int64), \n        \"CVC - Normal\"               : tf.io.FixedLenFeature([], tf.int64), \n        \"Swan Ganz Catheter Present\" : tf.io.FixedLenFeature([], tf.int64),\n    }\n    \n    def __init__(self, image_size):\n        self.image_size = image_size\n        \n    def parse_function(self, example_proto):\n        example = tf.io.parse_single_example(example_proto, self.feature_description)\n        image = tf.io.decode_image(example['image'], channels=3)\n        label = [example['ETT - Abnormal'],\n                 example['ETT - Borderline'],\n                 example['ETT - Normal'],\n                 example['NGT - Abnormal'],\n                 example['NGT - Borderline'],\n                 example['NGT - Incompletely Imaged'],\n                 example['NGT - Normal'],\n                 example['CVC - Abnormal'],\n                 example['CVC - Borderline'],\n                 example['CVC - Normal'],\n                 example['Swan Ganz Catheter Present']]\n        return image, label \n    \n    def augment_function(self, image, label):\n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n        image = tf.image.random_contrast(image, 0.8, 1.2)\n        image = tf.image.random_brightness(image, 0.1)   \n        return image, label \n    \n    def process_function(self, image, label):\n        image.set_shape([None, self.image_size, self.image_size, 3])\n        label.set_shape([None, 11])\n        image = tf.image.resize(image, [self.image_size, self.image_size], 'bilinear')/255\n        return image, label\n            \n    def generator(self, files, batch_size=1, repeat=False, augment=False, shuffle=True):\n        AUTO = tf.data.experimental.AUTOTUNE\n        ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n        if shuffle: \n            opt = tf.data.Options()\n            opt.experimental_deterministic = False\n            ds = ds.with_options(opt)\n            ds = ds.shuffle(2000)\n        ds = ds.map(self.parse_function, num_parallel_calls=AUTO)\n        if repeat:\n            ds = ds.repeat()\n        if augment:\n            ds = ds.map(self.augment_function, num_parallel_calls=AUTO)\n        ds = ds.batch(batch_size)\n        ds = ds.map(self.process_function, num_parallel_calls=AUTO)\n        ds = ds.prefetch(AUTO)\n        return ds","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(name, input_shape, classes, output_bias=None):\n    \n    # Dictionary mapping name to model function\n    \n    EFFICIENT_NETS = {'B0': efn.EfficientNetB0, \n                      'B1': efn.EfficientNetB1, \n                      'B2': efn.EfficientNetB2, \n                      'B3': efn.EfficientNetB3, \n                      'B4': efn.EfficientNetB4, \n                      'B5': efn.EfficientNetB5, \n                      'B6': efn.EfficientNetB6,\n                      'B7': efn.EfficientNetB7}\n    \n    # Output layer bias initialization\n    \n    if output_bias is None:\n        output_bias = 'zeros'\n    else:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n        \n    \n    # Base model\n    \n    base_model = EFFICIENT_NETS[name](include_top=False, \n                                      weights='imagenet', \n                                      input_shape=input_shape)\n    \n    # Model\n    \n    inputs = tf.keras.Input(shape=input_shape)\n    x = base_model(inputs)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(classes, bias_initializer=output_bias)(x)\n    outputs = tf.keras.layers.Activation('sigmoid', dtype='float32')(x) # Supports mixed-precision training\n    \n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n        \n    metrics = [tf.keras.metrics.AUC(name='auc')]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callbacks\n- 모델 저장 (Validation AUC max 일 때)\n    - [tf.keras.callbacks.ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)\n- 모델의 개선이 없을 경우, Learning Rate를 조절해 모델의 개선을 유도\n    - [tf.keras.callbacks.ReduceLROnPlateau](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau) [[detail](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)]\n- 모니터링 되는 모델의 지표 개선이 멈췄을 때 학습 중지\n    - [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks(model_save_path, fold, verbose=1):\n    \n    verbose = int(verbose>0)\n    \n    if not os.path.exists(model_save_path):\n        os.makedirs(model_save_path)\n    \n    cpk_path = f'{model_save_path}/model-f{fold}.h5'\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=verbose\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_auc',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=10, \n        verbose=verbose\n    )\n    \n    \n    \n    callbacks = [checkpoint, reducelr, earlystop]\n    \n    return callbacks","execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### count_items : 에포크의 스텝수 세는데 사용"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","execution_count":46,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main Training Pipeline\n\n- (현재) 교차검증이 아닌 한번만 학습하는 코드"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds_val_auc = [None] * FOLDS # Store the validation auc for each fold\n\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n\nprint(f'Training...')\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(np.arange(NUM_TF_RECS))):\n    \n    print(f'\\n\\n{\"*\"*100} \\nFOLD: {fold+1}')\n    \n    # Input Pipeline ******************************************************\n    \n    train_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in train_idx)\n    valid_files = tf.io.gfile.glob(f'{DATA_PATH}/train_tfrecords/{idx:02}*.tfrec' for idx in valid_idx)\n    \n    ds = Dataset(IMG_SIZE)\n    \n    train_ds = ds.generator(train_files, \n                            BATCH_SIZE, #*REPLICAS, \n                            repeat=True, \n                            augment=True, \n                            shuffle=True)\n\n    valid_ds = ds.generator(valid_files, \n                            BATCH_SIZE, #*REPLICAS,  \n                            repeat=False, \n                            augment=False, \n                            shuffle=False)\n    \n    # Calculate the steps_per_epoch\n    \n    steps_per_epoch = count_items(train_files)//(BATCH_SIZE) *2 #*REPLICAS) * 2\n    \n    \n    # Build Model ******************************************************\n    \n    tf.keras.backend.clear_session()\n        \n    with strategy.scope():\n        model = create_model(name=EFF_NET, \n                             input_shape=(IMG_SIZE,IMG_SIZE,3), \n                             classes=11)\n\n        model = compile_model(model, lr=0.0001)\n        model.summary()\n        \n    print(f'\\nModel initialized and compiled: EfficientNet-{EFF_NET}')\n    \n        \n    # Train ******************************************************\n    \n    callbacks = create_callbacks(MODEL_PATH, fold+1, verbose=VERBOSE)\n                                # MODEL_PATH = '/kaggle/working/models'\n\n    print(f'\\nModel training...\\n')\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS, \n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_ds, \n                        callbacks=callbacks,\n                        verbose=VERBOSE)\n    \n    # Save acc for each fold in a list\n    folds_val_auc[fold] = max(history.history['val_auc'])\n    \n    print(f'\\nModel trained \\n\\nFOLD-{fold+1} Validation AUC = {folds_val_auc[fold]}')\n    \n    break","execution_count":null,"outputs":[{"output_type":"stream","text":"Training...\n\n\n**************************************************************************************************** \nFOLD: 1\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nefficientnet-b0 (Functional) (None, 7, 7, 1280)        4049564   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 11)                14091     \n_________________________________________________________________\nactivation (Activation)      (None, 11)                0         \n=================================================================\nTotal params: 4,063,655\nTrainable params: 4,021,639\nNon-trainable params: 42,016\n_________________________________________________________________\n\nModel initialized and compiled: EfficientNet-B0\n\nModel training...\n\nEpoch 1/25\n1410/1410 - 267s - loss: 0.3160 - auc: 0.9103 - val_loss: 0.2982 - val_auc: 0.9379\n\nEpoch 00001: val_auc improved from -inf to 0.93786, saving model to /kaggle/working/models/model-f1.h5\nEpoch 2/25\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 학습훈련 그래프"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef plot_hist(hist):\n    plt.plot(hist.history['auc'], 'r', label='train auc')\n    plt.plot(hist.history['val_auc'], 'g', label='val auc')\n    plt.title(\"model auc\")\n    plt.ylabel(\"auc\")\n    plt.xlabel(\"epoch\")\n    plt.legend(loc='upper left')\n    plt.show()\n\n\nplot_hist(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist.history.key()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df = pd.DataFrame(hist.history) \nhist_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df.to_csv(\"hist_{EFF_NET}.csv\", mode='w')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'df_name.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}